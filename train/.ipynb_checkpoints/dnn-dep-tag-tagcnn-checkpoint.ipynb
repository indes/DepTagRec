{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import keras as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow as tf\n",
    "import pymongo\n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import string, re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate,MaxPooling1D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import keras as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 200000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host=\"192.168.0.106\", port=29197)\n",
    "client[\"github\"].authenticate(\"github\", \"git332\", \"github\")\n",
    "db = client[\"github\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_set = [x[\"name\"] for x in db.project_lang_30.find()]\n",
    "npm_tag_set = [\"npm_\"+x[\"name\"] for x in db.npm_tag_stem_top100.find()]\n",
    "pkg_tag_set = [\"pkg_\"+x[\"name\"] for x in db.composer_tag_stem_top100.find()]\n",
    "pypi_tag_set = [\"pypi_\"+x[\"name\"] for x in db.pypi_tag_stem_top100.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_col = [\"file_npm\", \"file_pypi\", \"file_composer\"]\n",
    "train_col.extend(lang_set)\n",
    "train_col.extend(npm_tag_set)\n",
    "train_col.extend(pkg_tag_set)\n",
    "train_col.extend(pypi_tag_set)\n",
    "len(train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set = [x[\"name\"] for x in db.project_tag_more_than_100.find()]\n",
    "len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.ldamodel.LdaModel.load('../model/readme_lda_256.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_link</th>\n",
       "      <th>file_readme</th>\n",
       "      <th>file_npm</th>\n",
       "      <th>file_pypi</th>\n",
       "      <th>file_composer</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>HTML</th>\n",
       "      <th>CSS</th>\n",
       "      <th>Python</th>\n",
       "      <th>Shell</th>\n",
       "      <th>...</th>\n",
       "      <th>pytorch</th>\n",
       "      <th>cach</th>\n",
       "      <th>laravel</th>\n",
       "      <th>data-sci</th>\n",
       "      <th>natural-language-process</th>\n",
       "      <th>authent</th>\n",
       "      <th>computer-vis</th>\n",
       "      <th>compos</th>\n",
       "      <th>python3</th>\n",
       "      <th>yii2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>welcom freecodecamp org s open sourc codebas c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941868</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vuejs/vue</td>\n",
       "      <td>support vue jsvue js mit licens open sourc pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976735</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/twbs/bootstrap</td>\n",
       "      <td>bootstrap sleek intuit power end framework fas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494735</td>\n",
       "      <td>0.182466</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/facebook/react</td>\n",
       "      <td>react middot react javascript librari build us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951378</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 project_link  \\\n",
       "0  /freeCodeCamp/freeCodeCamp   \n",
       "1                  /vuejs/vue   \n",
       "2             /twbs/bootstrap   \n",
       "3             /facebook/react   \n",
       "\n",
       "                                         file_readme  file_npm  file_pypi  \\\n",
       "0  welcom freecodecamp org s open sourc codebas c...         1          0   \n",
       "1  support vue jsvue js mit licens open sourc pro...         1          0   \n",
       "2  bootstrap sleek intuit power end framework fas...         1          0   \n",
       "3  react middot react javascript librari build us...         1          0   \n",
       "\n",
       "   file_composer  JavaScript      HTML       CSS    Python     Shell  ...  \\\n",
       "0              0    0.941868  0.017145  0.039971  0.000000  0.001017  ...   \n",
       "1              0    0.976735  0.006227  0.003945  0.000000  0.001170  ...   \n",
       "2              0    0.494735  0.182466  0.320497  0.000000  0.001512  ...   \n",
       "3              0    0.951378  0.017036  0.003504  0.000079  0.001854  ...   \n",
       "\n",
       "   pytorch  cach  laravel  data-sci  natural-language-process  authent  \\\n",
       "0        0     0        0         0                         0        0   \n",
       "1        0     0        0         0                         0        0   \n",
       "2        0     0        0         0                         0        0   \n",
       "3        0     0        0         0                         0        0   \n",
       "\n",
       "   computer-vis  compos  python3  yii2  \n",
       "0             0       0        0     0  \n",
       "1             0       0        0     0  \n",
       "2             0       0        0     0  \n",
       "3             0       0        0     0  \n",
       "\n",
       "[4 rows x 451 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv(\"../data/data_raw.csv\", index_col=0)\n",
    "data_raw.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = np.array(data_raw[tag_set]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_x = data_raw[\"file_readme\"].fillna(\"_##_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(readme_x))\n",
    "readme_x_tz = tokenizer.texts_to_sequences(readme_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pad the sentences \n",
    "train_X_seq = pad_sequences(readme_x_tz, maxlen=maxlen)\n",
    "train_X_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_minus_readme = data_raw[train_col]\n",
    "data_minus_readme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train_X_seq, data_tag, train_size=0.75, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19100, 300), (6367, 300))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model define\n",
    "\n",
    "\n",
    "\n",
    "# model = K.models.Sequential()\n",
    "# model.add(Embedding(len(vocab), 100, input_length=300))\n",
    "# model.add(Flatten())\n",
    "# model.add(K.layers.Dense(units=200, input_dim=100, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.Dense(units=200, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.Dense(units=200, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.Dense(units=1, kernel_initializer=init, activation='relu'))\n",
    "# model.compile(loss='mean_squared_error', optimizer=simple_adam, metrics=['categorical_accuracy'])\n",
    "\n",
    "def BuildTextCNN(maxlen=200, max_features=20000, embed_size=64):\n",
    "    comment_seq = Input(shape=[maxlen], name='x_seq')\n",
    "    emb_comment = Embedding(max_features, embed_size)(comment_seq)\n",
    "    convs = []\n",
    "    filter_sizes = [2, 3, 4, 5]\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(filters=100, kernel_size=fsz, activation='relu')(emb_comment)\n",
    "        l_pool = MaxPooling1D(maxlen - fsz + 1)(l_conv)\n",
    "        l_pool = Flatten()(l_pool)\n",
    "        convs.append(l_pool)\n",
    "    merge = concatenate(convs, axis=1)\n",
    "    out = Dropout(0.5)(merge)\n",
    "    output = Dense(200, activation='relu')(out)\n",
    "    output = Dense(units=116, activation='relu')(output)\n",
    "    model = Model([comment_seq], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/li/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/ml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'simple_adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5b112161b1f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtextcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuildTextCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimple_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'simple_adam' is not defined"
     ]
    }
   ],
   "source": [
    "init = K.initializers.glorot_uniform(seed=1)\n",
    "simple_adam = K.optimizers.Adam(lr=0.0001)\n",
    "textcnn = BuildTextCNN(maxlen=maxlen,max_features=len(vocab))\n",
    "textcnn.compile(loss='mean_squared_error', optimizer=simple_adam, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training \n",
      "Epoch 1/20\n",
      "19100/19100 [==============================] - 52s 3ms/step - loss: 0.0285 - categorical_accuracy: 0.0053\n",
      "Epoch 2/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0257 - categorical_accuracy: 0.0024\n",
      "Epoch 3/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0236 - categorical_accuracy: 0.0014\n",
      "Epoch 4/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0225 - categorical_accuracy: 0.0017\n",
      "Epoch 5/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0222 - categorical_accuracy: 0.0017\n",
      "Epoch 6/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0221 - categorical_accuracy: 0.0011\n",
      "Epoch 7/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0220 - categorical_accuracy: 0.0014\n",
      "Epoch 8/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0219 - categorical_accuracy: 0.0012\n",
      "Epoch 9/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0219 - categorical_accuracy: 0.0013\n",
      "Epoch 10/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0218 - categorical_accuracy: 0.0018\n",
      "Epoch 11/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0217 - categorical_accuracy: 0.0014\n",
      "Epoch 12/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0216 - categorical_accuracy: 0.0015\n",
      "Epoch 13/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0214 - categorical_accuracy: 0.0018\n",
      "Epoch 14/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0213 - categorical_accuracy: 0.0020\n",
      "Epoch 15/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0211 - categorical_accuracy: 0.0016\n",
      "Epoch 16/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0210 - categorical_accuracy: 0.0023\n",
      "Epoch 17/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0208 - categorical_accuracy: 0.0030\n",
      "Epoch 18/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0206 - categorical_accuracy: 0.0074\n",
      "Epoch 19/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0204 - categorical_accuracy: 0.0139\n",
      "Epoch 20/20\n",
      "19100/19100 [==============================] - 50s 3ms/step - loss: 0.0201 - categorical_accuracy: 0.0263\n",
      "Training finished \n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_size = 1024\n",
    "max_epochs = 20\n",
    "print(\"Starting training \")\n",
    "h = textcnn.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs, shuffle=True, verbose=1)\n",
    "print(\"Training finished \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = textcnn.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02242246, 0.10954895, 0.12424034, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.46227467, 0.46580622,\n",
       "        0.47429875, 0.4757085 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01795216, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02767659, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00764878, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0],test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出分数不为0的项\n",
    "p_list = []\n",
    "for k in p:\n",
    "    p_tag = {}\n",
    "    for i, score in enumerate(k.tolist()):\n",
    "        if(score!=0):\n",
    "            p_tag[score] = i\n",
    "    p_list.append(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    return t/len(true_tag)\n",
    "\n",
    "def precision(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    if len(pre_tag) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return t/len(pre_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list_top5 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top5.append([p_list[i][k] for k in sorted(p_list[i].keys())][-5:])\n",
    "    \n",
    "p_list_top10 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top10.append([p_list[i][k] for k in sorted(p_list[i].keys())][-10:])\n",
    "    \n",
    "p_list_top116 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top116.append([p_list[i][k] for k in sorted(p_list[i].keys())][-116:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tag_real = []\n",
    "for row in test_y:\n",
    "    true_tag_real.append(row.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 300, 100)          44672500  \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 200)               6000200   \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 50,753,301\n",
      "Trainable params: 50,753,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "====================================\n",
      "Recall@116: 0.5891630410320823\n",
      "Precision@116: 0.22820462360053054\n",
      "F1-score@116: 0.33412152108639026\n",
      "\n",
      "Recall@10: 0.5809433891066031\n",
      "Precision@10: 0.233180511616195\n",
      "F1-score@10: 0.33278638932392296\n",
      "\n",
      "Recall@5: 0.4625438005444436\n",
      "Precision@5: 0.37204334851578436\n",
      "F1-score@5: 0.4123867581319618\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "recal_at_116_count = 0\n",
    "recal_at_10_count = 0\n",
    "recal_at_5_count = 0\n",
    "precision_at_116_count = 0\n",
    "precision_at_10_count = 0\n",
    "precision_at_5_count = 0\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_10_count += recall(true_tag_real[i], p_list_top10[i])\n",
    "\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_5_count += recall(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_116_count += recall(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_10_count += precision(true_tag_real[i], p_list_top10[i])    \n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_5_count += precision(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_116_count += precision(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "recall_at_116 = recal_at_116_count/len(true_tag_real)\n",
    "recall_at_10 = recal_at_10_count/len(true_tag_real)\n",
    "recall_at_5 = recal_at_5_count/len(true_tag_real)\n",
    "precision_at_116 = precision_at_116_count/len(true_tag_real)\n",
    "precision_at_10 = precision_at_10_count/len(true_tag_real)\n",
    "precision_at_5 = precision_at_5_count/len(true_tag_real)\n",
    "\n",
    "textcnn.summary()\n",
    "print()\n",
    "print(\"====================================\")\n",
    "print(\"Recall@116: {}\".format(recall_at_116))\n",
    "print(\"Precision@116: {}\".format(precision_at_116_count/len(true_tag_real)))\n",
    "print(\"F1-score@116: {}\".format((2*recall_at_116*precision_at_10)/(recall_at_116+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@10: {}\".format(recall_at_10))\n",
    "print(\"Precision@10: {}\".format(precision_at_10_count/len(true_tag_real)))\n",
    "print(\"F1-score@10: {}\".format((2*recall_at_10*precision_at_10)/(recall_at_10+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@5: {}\".format(recall_at_5))\n",
    "print(\"Precision@5: {}\".format(precision_at_5_count/len(true_tag_real)))\n",
    "print(\"F1-score@5: {}\".format((2*recall_at_5*precision_at_5)/(recall_at_5+precision_at_5)))\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "textcnn.save(\"../model/textcnn-{}.h5\".format(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
