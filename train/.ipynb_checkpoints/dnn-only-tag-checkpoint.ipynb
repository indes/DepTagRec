{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import keras as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow as tf\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host=\"192.168.0.106\", port=29197)\n",
    "client[\"github\"].authenticate(\"github\", \"git332\", \"github\")\n",
    "db = client[\"github\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_set = [x[\"name\"] for x in db.project_lang_30.find()]\n",
    "npm_tag_set = [\"npm_\"+x[\"name\"] for x in db.npm_tag_stem_top100.find()]\n",
    "pkg_tag_set = [\"pkg_\"+x[\"name\"] for x in db.composer_tag_stem_top100.find()]\n",
    "pypi_tag_set = [\"pypi_\"+x[\"name\"] for x in db.pypi_tag_stem_top100.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_col = [\"file_npm\", \"file_pypi\", \"file_composer\"]\n",
    "train_col.extend(lang_set)\n",
    "train_col.extend(npm_tag_set)\n",
    "train_col.extend(pkg_tag_set)\n",
    "train_col.extend(pypi_tag_set)\n",
    "len(train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set = [x[\"name\"] for x in db.project_tag_more_than_100.find()]\n",
    "len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.ldamodel.LdaModel.load('../model/readme_lda_{}.model'.format(lda_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_link</th>\n",
       "      <th>file_readme</th>\n",
       "      <th>file_npm</th>\n",
       "      <th>file_pypi</th>\n",
       "      <th>file_composer</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>HTML</th>\n",
       "      <th>CSS</th>\n",
       "      <th>Python</th>\n",
       "      <th>Shell</th>\n",
       "      <th>...</th>\n",
       "      <th>pytorch</th>\n",
       "      <th>cach</th>\n",
       "      <th>laravel</th>\n",
       "      <th>data-sci</th>\n",
       "      <th>natural-language-process</th>\n",
       "      <th>authent</th>\n",
       "      <th>computer-vis</th>\n",
       "      <th>compos</th>\n",
       "      <th>python3</th>\n",
       "      <th>yii2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>welcom freecodecamp org s open sourc codebas c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941868</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vuejs/vue</td>\n",
       "      <td>support vue jsvue js mit licens open sourc pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976735</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/twbs/bootstrap</td>\n",
       "      <td>bootstrap sleek intuit power end framework fas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494735</td>\n",
       "      <td>0.182466</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/facebook/react</td>\n",
       "      <td>react middot react javascript librari build us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951378</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 project_link  \\\n",
       "0  /freeCodeCamp/freeCodeCamp   \n",
       "1                  /vuejs/vue   \n",
       "2             /twbs/bootstrap   \n",
       "3             /facebook/react   \n",
       "\n",
       "                                         file_readme  file_npm  file_pypi  \\\n",
       "0  welcom freecodecamp org s open sourc codebas c...         1          0   \n",
       "1  support vue jsvue js mit licens open sourc pro...         1          0   \n",
       "2  bootstrap sleek intuit power end framework fas...         1          0   \n",
       "3  react middot react javascript librari build us...         1          0   \n",
       "\n",
       "   file_composer  JavaScript      HTML       CSS    Python     Shell  ...  \\\n",
       "0              0    0.941868  0.017145  0.039971  0.000000  0.001017  ...   \n",
       "1              0    0.976735  0.006227  0.003945  0.000000  0.001170  ...   \n",
       "2              0    0.494735  0.182466  0.320497  0.000000  0.001512  ...   \n",
       "3              0    0.951378  0.017036  0.003504  0.000079  0.001854  ...   \n",
       "\n",
       "   pytorch  cach  laravel  data-sci  natural-language-process  authent  \\\n",
       "0        0     0        0         0                         0        0   \n",
       "1        0     0        0         0                         0        0   \n",
       "2        0     0        0         0                         0        0   \n",
       "3        0     0        0         0                         0        0   \n",
       "\n",
       "   computer-vis  compos  python3  yii2  \n",
       "0             0       0        0     0  \n",
       "1             0       0        0     0  \n",
       "2             0       0        0     0  \n",
       "3             0       0        0     0  \n",
       "\n",
       "[4 rows x 451 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv(\"../data/data_raw_tagonehot.csv\", index_col=0)\n",
    "data_raw.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = np.array(data_raw[tag_set]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 333)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_minus_readme = data_raw[train_col]\n",
    "data_minus_readme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25467"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_list = list(data_raw.file_readme)\n",
    "corpus = []\n",
    "\n",
    "for post in readme_list:\n",
    "    \n",
    "    corpus.append([word for word in str(post).strip().lower().split()])\n",
    "\n",
    "len(readme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(corpus)\n",
    "doc_bow = dictionary.doc2bow(corpus[0])\n",
    "lda_list = lda[doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lda = [lda[dictionary.doc2bow(doc)] for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = []\n",
    "\n",
    "for post in corpus_lda:\n",
    "    arr = np.zeros(lda_dim)\n",
    "    for elem in post:\n",
    "        arr[elem[0]] = elem[1]\n",
    "    \n",
    "    data_matrix.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 256)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x_np = np.array(data_matrix)\n",
    "data_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_feature = np.concatenate((data_x_np,data_minus_readme),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_feature.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_x_np[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_full_feature, data_tag, train_size=0.75, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19100, 6367)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x), len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU, Softmax\n",
    "input_dim = data_full_feature.shape[1]\n",
    "lr = 0.0001\n",
    "init = K.initializers.glorot_uniform(seed=1)\n",
    "simple_adam = K.optimizers.RMSprop(lr=lr)\n",
    "model = K.models.Sequential()\n",
    "act = K.layers.advanced_activations.PReLU()\n",
    "\n",
    "model.add(K.layers.Dense(units=600, input_dim=input_dim, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "# model.add(act)\n",
    "# model.add(K.layers.Dense(units=600, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(units=400, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "# model.add(act)\n",
    "# model.add(K.layers.BatchNormalization())\n",
    "\n",
    "model.add(K.layers.Dense(units=200, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "# model.add(act)\n",
    "# model.add(K.layers.BatchNormalization())\n",
    "\n",
    "model.add(K.layers.Dense(units=116, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "model.compile(loss='mean_squared_error', optimizer=simple_adam, metrics=['top_k_categorical_accuracy', 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training \n",
      "Epoch 1/70\n",
      "19100/19100 [==============================] - 2s 128us/step - loss: 0.0183 - top_k_categorical_accuracy: 0.5319 - categorical_accuracy: 0.3238\n",
      "Epoch 2/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0150 - top_k_categorical_accuracy: 0.5942 - categorical_accuracy: 0.2604\n",
      "Epoch 3/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0145 - top_k_categorical_accuracy: 0.6096 - categorical_accuracy: 0.2435\n",
      "Epoch 4/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0142 - top_k_categorical_accuracy: 0.6270 - categorical_accuracy: 0.2490\n",
      "Epoch 5/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0140 - top_k_categorical_accuracy: 0.6389 - categorical_accuracy: 0.2497\n",
      "Epoch 6/70\n",
      "19100/19100 [==============================] - 1s 61us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6471 - categorical_accuracy: 0.2461\n",
      "Epoch 7/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0137 - top_k_categorical_accuracy: 0.6533 - categorical_accuracy: 0.2479\n",
      "Epoch 8/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6591 - categorical_accuracy: 0.2424\n",
      "Epoch 9/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6664 - categorical_accuracy: 0.2469\n",
      "Epoch 10/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6691 - categorical_accuracy: 0.2472\n",
      "Epoch 11/70\n",
      "19100/19100 [==============================] - 1s 59us/step - loss: 0.0133 - top_k_categorical_accuracy: 0.6741 - categorical_accuracy: 0.2455\n",
      "Epoch 12/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0132 - top_k_categorical_accuracy: 0.6780 - categorical_accuracy: 0.2439\n",
      "Epoch 13/70\n",
      "19100/19100 [==============================] - 1s 59us/step - loss: 0.0131 - top_k_categorical_accuracy: 0.6807 - categorical_accuracy: 0.2437\n",
      "Epoch 14/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0130 - top_k_categorical_accuracy: 0.6827 - categorical_accuracy: 0.2422\n",
      "Epoch 15/70\n",
      "19100/19100 [==============================] - 1s 61us/step - loss: 0.0130 - top_k_categorical_accuracy: 0.6849 - categorical_accuracy: 0.2445\n",
      "Epoch 16/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0129 - top_k_categorical_accuracy: 0.6892 - categorical_accuracy: 0.2421\n",
      "Epoch 17/70\n",
      "19100/19100 [==============================] - 1s 59us/step - loss: 0.0128 - top_k_categorical_accuracy: 0.6915 - categorical_accuracy: 0.2430\n",
      "Epoch 18/70\n",
      "19100/19100 [==============================] - 1s 61us/step - loss: 0.0127 - top_k_categorical_accuracy: 0.6942 - categorical_accuracy: 0.2499\n",
      "Epoch 19/70\n",
      "19100/19100 [==============================] - 1s 59us/step - loss: 0.0127 - top_k_categorical_accuracy: 0.6969 - categorical_accuracy: 0.2423\n",
      "Epoch 20/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0126 - top_k_categorical_accuracy: 0.7003 - categorical_accuracy: 0.2443\n",
      "Epoch 21/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0125 - top_k_categorical_accuracy: 0.7012 - categorical_accuracy: 0.2492\n",
      "Epoch 22/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0124 - top_k_categorical_accuracy: 0.7039 - categorical_accuracy: 0.2489\n",
      "Epoch 23/70\n",
      "19100/19100 [==============================] - 1s 61us/step - loss: 0.0124 - top_k_categorical_accuracy: 0.7082 - categorical_accuracy: 0.2517\n",
      "Epoch 24/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0123 - top_k_categorical_accuracy: 0.7097 - categorical_accuracy: 0.2557\n",
      "Epoch 25/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0123 - top_k_categorical_accuracy: 0.7115 - categorical_accuracy: 0.2502\n",
      "Epoch 26/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0122 - top_k_categorical_accuracy: 0.7133 - categorical_accuracy: 0.2513\n",
      "Epoch 27/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0121 - top_k_categorical_accuracy: 0.7168 - categorical_accuracy: 0.2531\n",
      "Epoch 28/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0121 - top_k_categorical_accuracy: 0.7181 - categorical_accuracy: 0.2583\n",
      "Epoch 29/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0120 - top_k_categorical_accuracy: 0.7214 - categorical_accuracy: 0.2534\n",
      "Epoch 30/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0119 - top_k_categorical_accuracy: 0.7241 - categorical_accuracy: 0.2531\n",
      "Epoch 31/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0118 - top_k_categorical_accuracy: 0.7264 - categorical_accuracy: 0.2589\n",
      "Epoch 32/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0118 - top_k_categorical_accuracy: 0.7295 - categorical_accuracy: 0.2593\n",
      "Epoch 33/70\n",
      "19100/19100 [==============================] - 1s 60us/step - loss: 0.0117 - top_k_categorical_accuracy: 0.7293 - categorical_accuracy: 0.2570\n",
      "Epoch 34/70\n",
      "15616/19100 [=======================>......] - ETA: 0s - loss: 0.0118 - top_k_categorical_accuracy: 0.7310 - categorical_accuracy: 0.2622"
     ]
    }
   ],
   "source": [
    "b_size = 256\n",
    "max_epochs = 70\n",
    "print(\"Starting training \")\n",
    "h = model.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs, shuffle=True, verbose=1)\n",
    "print(\"Training finished \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0],test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出分数不为0的项\n",
    "p_list = []\n",
    "for k in p:\n",
    "    p_tag = {}\n",
    "    for i, score in enumerate(k.tolist()):\n",
    "        if(score!=0):\n",
    "            p_tag[score] = i\n",
    "    p_list.append(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    return t/len(true_tag)\n",
    "\n",
    "def precision(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    if len(pre_tag) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return t/len(pre_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list_top5 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top5.append([p_list[i][k] for k in sorted(p_list[i].keys())][-5:])\n",
    "    \n",
    "p_list_top10 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top10.append([p_list[i][k] for k in sorted(p_list[i].keys())][-10:])\n",
    "    \n",
    "p_list_top116 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top116.append([p_list[i][k] for k in sorted(p_list[i].keys())][-116:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0,0,2]).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tag_real = []\n",
    "for row in test_y:\n",
    "    true_tag_real.append(row.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recal_at_116_count = 0\n",
    "recal_at_10_count = 0\n",
    "recal_at_5_count = 0\n",
    "precision_at_116_count = 0\n",
    "precision_at_10_count = 0\n",
    "precision_at_5_count = 0\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_10_count += recall(true_tag_real[i], p_list_top10[i])\n",
    "\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_5_count += recall(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_116_count += recall(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_10_count += precision(true_tag_real[i], p_list_top10[i])    \n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_5_count += precision(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_116_count += precision(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "recall_at_116 = recal_at_116_count/len(true_tag_real)\n",
    "recall_at_10 = recal_at_10_count/len(true_tag_real)\n",
    "recall_at_5 = recal_at_5_count/len(true_tag_real)\n",
    "precision_at_116 = precision_at_116_count/len(true_tag_real)\n",
    "precision_at_10 = precision_at_10_count/len(true_tag_real)\n",
    "precision_at_5 = precision_at_5_count/len(true_tag_real)\n",
    "\n",
    "\n",
    "print(\"lr: {} b_size: {} max_epochs: {} lda_dim: {} \".format(lr, b_size, max_epochs, lda_dim))\n",
    "\n",
    "model.summary()\n",
    "print()\n",
    "print(\"====================================\")\n",
    "print(\"Recall@116: {}\".format(recall_at_116))\n",
    "print(\"Precision@116: {}\".format(precision_at_116_count/len(true_tag_real)))\n",
    "print(\"F1-score@116: {}\".format((2*recall_at_116*precision_at_10)/(recall_at_116+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@10: {}\".format(recall_at_10))\n",
    "print(\"Precision@10: {}\".format(precision_at_10_count/len(true_tag_real)))\n",
    "print(\"F1-score@10: {}\".format((2*recall_at_10*precision_at_10)/(recall_at_10+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@5: {}\".format(recall_at_5))\n",
    "print(\"Precision@5: {}\".format(precision_at_5_count/len(true_tag_real)))\n",
    "print(\"F1-score@5: {}\".format((2*recall_at_5*precision_at_5)/(recall_at_5+precision_at_5)))\n",
    "print(\"====================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
