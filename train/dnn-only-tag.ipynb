{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import keras as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow as tf\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host=\"192.168.0.106\", port=29197)\n",
    "client[\"github\"].authenticate(\"github\", \"git332\", \"github\")\n",
    "db = client[\"github\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_set = [x[\"name\"] for x in db.project_lang_30.find()]\n",
    "npm_tag_set = [\"npm_\"+x[\"name\"] for x in db.npm_tag_stem_top100.find()]\n",
    "pkg_tag_set = [\"pkg_\"+x[\"name\"] for x in db.composer_tag_stem_top100.find()]\n",
    "pypi_tag_set = [\"pypi_\"+x[\"name\"] for x in db.pypi_tag_stem_top100.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_col = [\"file_npm\", \"file_pypi\", \"file_composer\"]\n",
    "train_col.extend(lang_set)\n",
    "train_col.extend(npm_tag_set)\n",
    "train_col.extend(pkg_tag_set)\n",
    "train_col.extend(pypi_tag_set)\n",
    "len(train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set = [x[\"name\"] for x in db.project_tag_more_than_100.find()]\n",
    "len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.ldamodel.LdaModel.load('../model/readme_lda_{}.model'.format(lda_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_link</th>\n",
       "      <th>file_readme</th>\n",
       "      <th>file_npm</th>\n",
       "      <th>file_pypi</th>\n",
       "      <th>file_composer</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>HTML</th>\n",
       "      <th>CSS</th>\n",
       "      <th>Python</th>\n",
       "      <th>Shell</th>\n",
       "      <th>...</th>\n",
       "      <th>pytorch</th>\n",
       "      <th>cach</th>\n",
       "      <th>laravel</th>\n",
       "      <th>data-sci</th>\n",
       "      <th>natural-language-process</th>\n",
       "      <th>authent</th>\n",
       "      <th>computer-vis</th>\n",
       "      <th>compos</th>\n",
       "      <th>python3</th>\n",
       "      <th>yii2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>welcom freecodecamp org s open sourc codebas c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941868</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vuejs/vue</td>\n",
       "      <td>support vue jsvue js mit licens open sourc pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976735</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/twbs/bootstrap</td>\n",
       "      <td>bootstrap sleek intuit power end framework fas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494735</td>\n",
       "      <td>0.182466</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/facebook/react</td>\n",
       "      <td>react middot react javascript librari build us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951378</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 project_link  \\\n",
       "0  /freeCodeCamp/freeCodeCamp   \n",
       "1                  /vuejs/vue   \n",
       "2             /twbs/bootstrap   \n",
       "3             /facebook/react   \n",
       "\n",
       "                                         file_readme  file_npm  file_pypi  \\\n",
       "0  welcom freecodecamp org s open sourc codebas c...         1          0   \n",
       "1  support vue jsvue js mit licens open sourc pro...         1          0   \n",
       "2  bootstrap sleek intuit power end framework fas...         1          0   \n",
       "3  react middot react javascript librari build us...         1          0   \n",
       "\n",
       "   file_composer  JavaScript      HTML       CSS    Python     Shell  ...  \\\n",
       "0              0    0.941868  0.017145  0.039971  0.000000  0.001017  ...   \n",
       "1              0    0.976735  0.006227  0.003945  0.000000  0.001170  ...   \n",
       "2              0    0.494735  0.182466  0.320497  0.000000  0.001512  ...   \n",
       "3              0    0.951378  0.017036  0.003504  0.000079  0.001854  ...   \n",
       "\n",
       "   pytorch  cach  laravel  data-sci  natural-language-process  authent  \\\n",
       "0        0     0        0         0                         0        0   \n",
       "1        0     0        0         0                         0        0   \n",
       "2        0     0        0         0                         0        0   \n",
       "3        0     0        0         0                         0        0   \n",
       "\n",
       "   computer-vis  compos  python3  yii2  \n",
       "0             0       0        0     0  \n",
       "1             0       0        0     0  \n",
       "2             0       0        0     0  \n",
       "3             0       0        0     0  \n",
       "\n",
       "[4 rows x 451 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv(\"../data/data_raw_tagonehot.csv\", index_col=0)\n",
    "data_raw.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = np.array(data_raw[tag_set]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 333)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_minus_readme = data_raw[train_col]\n",
    "data_minus_readme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25467"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_list = list(data_raw.file_readme)\n",
    "corpus = []\n",
    "\n",
    "for post in readme_list:\n",
    "    \n",
    "    corpus.append([word for word in str(post).strip().lower().split()])\n",
    "\n",
    "len(readme_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(corpus)\n",
    "doc_bow = dictionary.doc2bow(corpus[0])\n",
    "lda_list = lda[doc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lda = [lda[dictionary.doc2bow(doc)] for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = []\n",
    "\n",
    "for post in corpus_lda:\n",
    "    arr = np.zeros(lda_dim)\n",
    "    for elem in post:\n",
    "        arr[elem[0]] = elem[1]\n",
    "    \n",
    "    data_matrix.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 256)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x_np = np.array(data_matrix)\n",
    "data_x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full_feature = np.concatenate((data_x_np,data_minus_readme),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_feature.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 333)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_minus_readme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_x_np[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_minus_readme, data_tag, train_size=0.75, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19100, 333), (6367, 333))"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU, Softmax\n",
    "input_dim = train_x.shape[1]\n",
    "lr = 0.0001\n",
    "init = K.initializers.glorot_uniform(seed=1)\n",
    "simple_adam = K.optimizers.RMSprop(lr=lr)\n",
    "model = K.models.Sequential()\n",
    "act = K.layers.advanced_activations.PReLU()\n",
    "\n",
    "model.add(K.layers.Dense(units=600, input_dim=input_dim, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "# model.add(act)\n",
    "# model.add(K.layers.Dense(units=600, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.BatchNormalization())\n",
    "model.add(K.layers.Dense(units=400, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "# model.add(act)\n",
    "# model.add(K.layers.BatchNormalization())\n",
    "\n",
    "model.add(K.layers.Dense(units=200, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "# model.add(act)\n",
    "# model.add(K.layers.BatchNormalization())\n",
    "\n",
    "model.add(K.layers.Dense(units=116, kernel_initializer=init,activation=LeakyReLU(0.7)))\n",
    "model.compile(loss='mean_squared_error', optimizer=simple_adam, metrics=['top_k_categorical_accuracy', 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training \n",
      "Epoch 1/70\n",
      "19100/19100 [==============================] - 2s 121us/step - loss: 0.0216 - top_k_categorical_accuracy: 0.5223 - categorical_accuracy: 0.2285\n",
      "Epoch 2/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0160 - top_k_categorical_accuracy: 0.5940 - categorical_accuracy: 0.2099\n",
      "Epoch 3/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0152 - top_k_categorical_accuracy: 0.6048 - categorical_accuracy: 0.2121\n",
      "Epoch 4/70\n",
      "19100/19100 [==============================] - 1s 52us/step - loss: 0.0149 - top_k_categorical_accuracy: 0.6113 - categorical_accuracy: 0.2082\n",
      "Epoch 5/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0146 - top_k_categorical_accuracy: 0.6248 - categorical_accuracy: 0.2194\n",
      "Epoch 6/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0145 - top_k_categorical_accuracy: 0.6300 - categorical_accuracy: 0.2232\n",
      "Epoch 7/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0144 - top_k_categorical_accuracy: 0.6311 - categorical_accuracy: 0.2255\n",
      "Epoch 8/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0143 - top_k_categorical_accuracy: 0.6354 - categorical_accuracy: 0.2291\n",
      "Epoch 9/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0143 - top_k_categorical_accuracy: 0.6386 - categorical_accuracy: 0.2271\n",
      "Epoch 10/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0142 - top_k_categorical_accuracy: 0.6391 - categorical_accuracy: 0.2293\n",
      "Epoch 11/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0142 - top_k_categorical_accuracy: 0.6410 - categorical_accuracy: 0.2279\n",
      "Epoch 12/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0142 - top_k_categorical_accuracy: 0.6435 - categorical_accuracy: 0.2274\n",
      "Epoch 13/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0141 - top_k_categorical_accuracy: 0.6434 - categorical_accuracy: 0.2261\n",
      "Epoch 14/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0141 - top_k_categorical_accuracy: 0.6448 - categorical_accuracy: 0.2275\n",
      "Epoch 15/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0141 - top_k_categorical_accuracy: 0.6461 - categorical_accuracy: 0.2251\n",
      "Epoch 16/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0140 - top_k_categorical_accuracy: 0.6485 - categorical_accuracy: 0.2287\n",
      "Epoch 17/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0140 - top_k_categorical_accuracy: 0.6494 - categorical_accuracy: 0.2296\n",
      "Epoch 18/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0140 - top_k_categorical_accuracy: 0.6504 - categorical_accuracy: 0.2351\n",
      "Epoch 19/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0139 - top_k_categorical_accuracy: 0.6514 - categorical_accuracy: 0.2275\n",
      "Epoch 20/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0139 - top_k_categorical_accuracy: 0.6527 - categorical_accuracy: 0.2342\n",
      "Epoch 21/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0139 - top_k_categorical_accuracy: 0.6530 - categorical_accuracy: 0.2297\n",
      "Epoch 22/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0139 - top_k_categorical_accuracy: 0.6553 - categorical_accuracy: 0.2330\n",
      "Epoch 23/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0139 - top_k_categorical_accuracy: 0.6559 - categorical_accuracy: 0.2308\n",
      "Epoch 24/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0139 - top_k_categorical_accuracy: 0.6556 - categorical_accuracy: 0.2390\n",
      "Epoch 25/70\n",
      "19100/19100 [==============================] - 1s 52us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6577 - categorical_accuracy: 0.2351\n",
      "Epoch 26/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6588 - categorical_accuracy: 0.2306\n",
      "Epoch 27/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6593 - categorical_accuracy: 0.2345\n",
      "Epoch 28/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6606 - categorical_accuracy: 0.2370\n",
      "Epoch 29/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6585 - categorical_accuracy: 0.2338\n",
      "Epoch 30/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6606 - categorical_accuracy: 0.2396\n",
      "Epoch 31/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0138 - top_k_categorical_accuracy: 0.6619 - categorical_accuracy: 0.2378\n",
      "Epoch 32/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0137 - top_k_categorical_accuracy: 0.6629 - categorical_accuracy: 0.2327\n",
      "Epoch 33/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0137 - top_k_categorical_accuracy: 0.6628 - categorical_accuracy: 0.2357\n",
      "Epoch 34/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0137 - top_k_categorical_accuracy: 0.6639 - categorical_accuracy: 0.2398\n",
      "Epoch 35/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0137 - top_k_categorical_accuracy: 0.6652 - categorical_accuracy: 0.2416\n",
      "Epoch 36/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0137 - top_k_categorical_accuracy: 0.6645 - categorical_accuracy: 0.2352\n",
      "Epoch 37/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0137 - top_k_categorical_accuracy: 0.6659 - categorical_accuracy: 0.2364\n",
      "Epoch 38/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6649 - categorical_accuracy: 0.2384\n",
      "Epoch 39/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6676 - categorical_accuracy: 0.2413\n",
      "Epoch 40/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6672 - categorical_accuracy: 0.2428\n",
      "Epoch 41/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6683 - categorical_accuracy: 0.2372\n",
      "Epoch 42/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6671 - categorical_accuracy: 0.2404\n",
      "Epoch 43/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6683 - categorical_accuracy: 0.2366\n",
      "Epoch 44/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6710 - categorical_accuracy: 0.2399\n",
      "Epoch 45/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6700 - categorical_accuracy: 0.2388\n",
      "Epoch 46/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6689 - categorical_accuracy: 0.2438\n",
      "Epoch 47/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0136 - top_k_categorical_accuracy: 0.6687 - categorical_accuracy: 0.2377\n",
      "Epoch 48/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6712 - categorical_accuracy: 0.2414\n",
      "Epoch 49/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6708 - categorical_accuracy: 0.2398\n",
      "Epoch 50/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6724 - categorical_accuracy: 0.2392\n",
      "Epoch 51/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6716 - categorical_accuracy: 0.2412\n",
      "Epoch 52/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6713 - categorical_accuracy: 0.2373\n",
      "Epoch 53/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6740 - categorical_accuracy: 0.2398\n",
      "Epoch 54/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6733 - categorical_accuracy: 0.2371\n",
      "Epoch 55/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6751 - categorical_accuracy: 0.2402\n",
      "Epoch 56/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0135 - top_k_categorical_accuracy: 0.6735 - categorical_accuracy: 0.2382\n",
      "Epoch 57/70\n",
      "19100/19100 [==============================] - 1s 52us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6746 - categorical_accuracy: 0.2364\n",
      "Epoch 58/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6748 - categorical_accuracy: 0.2392\n",
      "Epoch 59/70\n",
      "19100/19100 [==============================] - 1s 52us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6743 - categorical_accuracy: 0.2395\n",
      "Epoch 60/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6756 - categorical_accuracy: 0.2380\n",
      "Epoch 61/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6759 - categorical_accuracy: 0.2362\n",
      "Epoch 62/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6760 - categorical_accuracy: 0.2390\n",
      "Epoch 63/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6779 - categorical_accuracy: 0.2353\n",
      "Epoch 64/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0134 - top_k_categorical_accuracy: 0.6768 - categorical_accuracy: 0.2390\n",
      "Epoch 65/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0133 - top_k_categorical_accuracy: 0.6771 - categorical_accuracy: 0.2396\n",
      "Epoch 66/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0133 - top_k_categorical_accuracy: 0.6779 - categorical_accuracy: 0.2353\n",
      "Epoch 67/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0133 - top_k_categorical_accuracy: 0.6760 - categorical_accuracy: 0.2363\n",
      "Epoch 68/70\n",
      "19100/19100 [==============================] - 1s 50us/step - loss: 0.0133 - top_k_categorical_accuracy: 0.6779 - categorical_accuracy: 0.2363\n",
      "Epoch 69/70\n",
      "19100/19100 [==============================] - 1s 51us/step - loss: 0.0133 - top_k_categorical_accuracy: 0.6784 - categorical_accuracy: 0.2317\n",
      "Epoch 70/70\n",
      "19100/19100 [==============================] - 1s 52us/step - loss: 0.0133 - top_k_categorical_accuracy: 0.6776 - categorical_accuracy: 0.2357\n",
      "Training finished \n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_size = 256\n",
    "max_epochs = 70\n",
    "print(\"Starting training \")\n",
    "h = model.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs, shuffle=True, verbose=1)\n",
    "print(\"Training finished \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.99190187e-02, -6.88938573e-02,  4.97753732e-02,  1.58765778e-01,\n",
       "         2.10351571e-02, -1.17918672e-02, -1.39034195e-02,  2.05532275e-03,\n",
       "        -1.55963534e-02, -2.55220151e-03, -3.25947627e-02, -1.82408486e-02,\n",
       "         8.68331432e-01,  8.63281727e-01,  8.71645033e-01,  8.51837754e-01,\n",
       "         8.45768631e-01, -1.38831278e-02, -2.26300228e-02,  6.70319330e-03,\n",
       "         1.10439807e-02, -4.11782647e-03,  8.25692993e-03, -2.43066382e-02,\n",
       "        -1.09302253e-02,  2.15638801e-03, -2.42224745e-02, -5.72637655e-03,\n",
       "        -9.68197640e-03, -8.12165439e-03, -1.68814007e-02,  7.84499943e-02,\n",
       "        -1.24975313e-02, -1.57340486e-02, -8.68360046e-03, -7.38475006e-03,\n",
       "        -1.71911586e-02, -9.29899421e-03, -2.87130177e-02, -8.40720069e-03,\n",
       "        -1.59693472e-02,  1.57315191e-02,  2.24599503e-02,  1.26017239e-02,\n",
       "        -3.15353423e-02,  2.08640769e-02, -2.58164257e-02,  2.06209384e-02,\n",
       "        -1.32190185e-02, -2.77736839e-02, -1.21625047e-02, -4.86988621e-03,\n",
       "        -3.72652919e-03, -1.86325517e-02,  4.11615241e-03, -2.02991590e-02,\n",
       "         2.52597500e-03, -1.90981217e-02,  5.75067895e-03, -1.63711980e-02,\n",
       "        -2.75662076e-02,  2.33354652e-03, -2.43505761e-02,  2.75567230e-02,\n",
       "         2.70019984e-03,  1.11473128e-02,  1.57544240e-02,  2.68909894e-02,\n",
       "        -3.01007926e-02,  4.84204385e-03, -7.44203513e-04, -5.50408429e-03,\n",
       "        -2.80064400e-02, -1.47740415e-03,  1.18747959e-03,  1.51216593e-02,\n",
       "         1.04643209e-02,  5.78515837e-03, -6.48163538e-03, -4.57994035e-03,\n",
       "         2.31034867e-02, -2.23320704e-02, -1.78173166e-02,  3.05623235e-03,\n",
       "        -1.16034774e-02, -1.35592744e-03,  3.91769782e-03, -1.91621259e-02,\n",
       "        -3.28059681e-03, -1.65678989e-02,  4.15925495e-03,  5.58457337e-03,\n",
       "         3.78068443e-03,  8.43222719e-03, -7.32861401e-04, -5.01376949e-03,\n",
       "        -3.04536708e-03, -2.35849409e-03, -1.60148405e-02,  1.30458176e-03,\n",
       "         4.51606512e-03, -8.60213023e-03, -1.70023157e-03, -5.03775338e-03,\n",
       "        -1.04671977e-02,  1.16468938e-02, -9.78464354e-03,  3.28512583e-03,\n",
       "         2.38890685e-02,  1.34138837e-02, -1.30807422e-02, -7.41553842e-04,\n",
       "         1.18899753e-03, -1.40516227e-02, -1.62893273e-02,  1.94856487e-02],\n",
       "       dtype=float32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0],test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出分数不为0的项\n",
    "p_list = []\n",
    "for k in p:\n",
    "    p_tag = {}\n",
    "    for i, score in enumerate(k.tolist()):\n",
    "        if(score!=0):\n",
    "            p_tag[score] = i\n",
    "    p_list.append(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    return t/len(true_tag)\n",
    "\n",
    "def precision(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    if len(pre_tag) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return t/len(pre_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list_top5 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top5.append([p_list[i][k] for k in sorted(p_list[i].keys())][-5:])\n",
    "    \n",
    "p_list_top10 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top10.append([p_list[i][k] for k in sorted(p_list[i].keys())][-10:])\n",
    "    \n",
    "p_list_top116 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top116.append([p_list[i][k] for k in sorted(p_list[i].keys())][-116:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2]),)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,0,2]).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tag_real = []\n",
    "for row in test_y:\n",
    "    true_tag_real.append(row.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001 b_size: 256 max_epochs: 70 lda_dim: 256 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 600)               200400    \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 116)               23316     \n",
      "=================================================================\n",
      "Total params: 544,316\n",
      "Trainable params: 544,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "====================================\n",
      "Recall@116: 1.0\n",
      "Precision@116: 0.02803788933238909\n",
      "F1-score@116: 0.43599159901250806\n",
      "\n",
      "Recall@10: 0.7974957467536397\n",
      "Precision@10: 0.27876550965917407\n",
      "F1-score@10: 0.41312331363813487\n",
      "\n",
      "Recall@5: 0.6421309145629875\n",
      "Precision@5: 0.49118894298727217\n",
      "F1-score@5: 0.5566082744996935\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "recal_at_116_count = 0\n",
    "recal_at_10_count = 0\n",
    "recal_at_5_count = 0\n",
    "precision_at_116_count = 0\n",
    "precision_at_10_count = 0\n",
    "precision_at_5_count = 0\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_10_count += recall(true_tag_real[i], p_list_top10[i])\n",
    "\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_5_count += recall(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_116_count += recall(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_10_count += precision(true_tag_real[i], p_list_top10[i])    \n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_5_count += precision(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_116_count += precision(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "recall_at_116 = recal_at_116_count/len(true_tag_real)\n",
    "recall_at_10 = recal_at_10_count/len(true_tag_real)\n",
    "recall_at_5 = recal_at_5_count/len(true_tag_real)\n",
    "precision_at_116 = precision_at_116_count/len(true_tag_real)\n",
    "precision_at_10 = precision_at_10_count/len(true_tag_real)\n",
    "precision_at_5 = precision_at_5_count/len(true_tag_real)\n",
    "\n",
    "\n",
    "print(\"lr: {} b_size: {} max_epochs: {} lda_dim: {} \".format(lr, b_size, max_epochs, lda_dim))\n",
    "\n",
    "model.summary()\n",
    "print()\n",
    "print(\"====================================\")\n",
    "print(\"Recall@116: {}\".format(recall_at_116))\n",
    "print(\"Precision@116: {}\".format(precision_at_116_count/len(true_tag_real)))\n",
    "print(\"F1-score@116: {}\".format((2*recall_at_116*precision_at_10)/(recall_at_116+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@10: {}\".format(recall_at_10))\n",
    "print(\"Precision@10: {}\".format(precision_at_10_count/len(true_tag_real)))\n",
    "print(\"F1-score@10: {}\".format((2*recall_at_10*precision_at_10)/(recall_at_10+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@5: {}\".format(recall_at_5))\n",
    "print(\"Precision@5: {}\".format(precision_at_5_count/len(true_tag_real)))\n",
    "print(\"F1-score@5: {}\".format((2*recall_at_5*precision_at_5)/(recall_at_5+precision_at_5)))\n",
    "print(\"====================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
