{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import Dictionary\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "import keras as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow as tf\n",
    "import pymongo\n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import string, re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate,MaxPooling1D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import keras as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 200000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 300 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host=\"192.168.0.106\", port=29197)\n",
    "client[\"github\"].authenticate(\"github\", \"git332\", \"github\")\n",
    "db = client[\"github\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_set = [x[\"name\"] for x in db.project_lang_30.find()]\n",
    "npm_tag_set = [\"npm_\"+x[\"name\"] for x in db.npm_tag_stem_top100.find()]\n",
    "pkg_tag_set = [\"pkg_\"+x[\"name\"] for x in db.composer_tag_stem_top100.find()]\n",
    "pypi_tag_set = [\"pypi_\"+x[\"name\"] for x in db.pypi_tag_stem_top100.find()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_col = [\"file_npm\", \"file_pypi\", \"file_composer\"]\n",
    "train_col.extend(lang_set)\n",
    "train_col.extend(npm_tag_set)\n",
    "train_col.extend(pkg_tag_set)\n",
    "train_col.extend(pypi_tag_set)\n",
    "len(train_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set = [x[\"name\"] for x in db.project_tag_more_than_100.find()]\n",
    "len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.ldamodel.LdaModel.load('../model/readme_lda_256.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_link</th>\n",
       "      <th>file_readme</th>\n",
       "      <th>file_npm</th>\n",
       "      <th>file_pypi</th>\n",
       "      <th>file_composer</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>HTML</th>\n",
       "      <th>CSS</th>\n",
       "      <th>Python</th>\n",
       "      <th>Shell</th>\n",
       "      <th>...</th>\n",
       "      <th>pytorch</th>\n",
       "      <th>cach</th>\n",
       "      <th>laravel</th>\n",
       "      <th>data-sci</th>\n",
       "      <th>natural-language-process</th>\n",
       "      <th>authent</th>\n",
       "      <th>computer-vis</th>\n",
       "      <th>compos</th>\n",
       "      <th>python3</th>\n",
       "      <th>yii2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/freeCodeCamp/freeCodeCamp</td>\n",
       "      <td>welcom freecodecamp org s open sourc codebas c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941868</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>0.039971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vuejs/vue</td>\n",
       "      <td>support vue jsvue js mit licens open sourc pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.976735</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/twbs/bootstrap</td>\n",
       "      <td>bootstrap sleek intuit power end framework fas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494735</td>\n",
       "      <td>0.182466</td>\n",
       "      <td>0.320497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/facebook/react</td>\n",
       "      <td>react middot react javascript librari build us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951378</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 project_link  \\\n",
       "0  /freeCodeCamp/freeCodeCamp   \n",
       "1                  /vuejs/vue   \n",
       "2             /twbs/bootstrap   \n",
       "3             /facebook/react   \n",
       "\n",
       "                                         file_readme  file_npm  file_pypi  \\\n",
       "0  welcom freecodecamp org s open sourc codebas c...         1          0   \n",
       "1  support vue jsvue js mit licens open sourc pro...         1          0   \n",
       "2  bootstrap sleek intuit power end framework fas...         1          0   \n",
       "3  react middot react javascript librari build us...         1          0   \n",
       "\n",
       "   file_composer  JavaScript      HTML       CSS    Python     Shell  ...  \\\n",
       "0              0    0.941868  0.017145  0.039971  0.000000  0.001017  ...   \n",
       "1              0    0.976735  0.006227  0.003945  0.000000  0.001170  ...   \n",
       "2              0    0.494735  0.182466  0.320497  0.000000  0.001512  ...   \n",
       "3              0    0.951378  0.017036  0.003504  0.000079  0.001854  ...   \n",
       "\n",
       "   pytorch  cach  laravel  data-sci  natural-language-process  authent  \\\n",
       "0        0     0        0         0                         0        0   \n",
       "1        0     0        0         0                         0        0   \n",
       "2        0     0        0         0                         0        0   \n",
       "3        0     0        0         0                         0        0   \n",
       "\n",
       "   computer-vis  compos  python3  yii2  \n",
       "0             0       0        0     0  \n",
       "1             0       0        0     0  \n",
       "2             0       0        0     0  \n",
       "3             0       0        0     0  \n",
       "\n",
       "[4 rows x 451 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_csv(\"../data/data_raw.csv\", index_col=0)\n",
    "data_raw.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = np.array(data_raw[tag_set]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_x = data_raw[\"file_readme\"].fillna(\"_##_\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(readme_x))\n",
    "readme_x_tz = tokenizer.texts_to_sequences(readme_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pad the sentences \n",
    "train_X_seq = pad_sequences(readme_x_tz, maxlen=maxlen)\n",
    "train_X_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_minus_readme = data_raw[train_col]\n",
    "data_minus_readme.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train_X_seq, data_tag, train_size=0.75, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19100, 300), (6367, 300))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model define\n",
    "\n",
    "\n",
    "\n",
    "# model = K.models.Sequential()\n",
    "# model.add(Embedding(len(vocab), 100, input_length=300))\n",
    "# model.add(Flatten())\n",
    "# model.add(K.layers.Dense(units=200, input_dim=100, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.Dense(units=200, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.Dense(units=200, kernel_initializer=init, activation='relu'))\n",
    "# model.add(K.layers.Dense(units=1, kernel_initializer=init, activation='relu'))\n",
    "# model.compile(loss='mean_squared_error', optimizer=simple_adam, metrics=['categorical_accuracy'])\n",
    "\n",
    "def BuildTextCNN(maxlen=200, max_features=20000, embed_size=64):\n",
    "    comment_seq = Input(shape=[maxlen], name='x_seq')\n",
    "    emb_comment = Embedding(max_features, embed_size)(comment_seq)\n",
    "    convs = []\n",
    "    filter_sizes = [2, 3, 4, 5]\n",
    "    for fsz in filter_sizes:\n",
    "        l_conv = Conv1D(filters=100, kernel_size=fsz, activation='relu')(emb_comment)\n",
    "        l_pool = MaxPooling1D(maxlen - fsz + 1)(l_conv)\n",
    "        l_pool = Flatten()(l_pool)\n",
    "        convs.append(l_pool)\n",
    "    merge = concatenate(convs, axis=1)\n",
    "    out = Dropout(0.5)(merge)\n",
    "    output = Dense(200, activation='relu')(out)\n",
    "    output = Dense(units=116, activation='relu')(output)\n",
    "    model = Model([comment_seq], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = K.initializers.glorot_uniform(seed=1)\n",
    "simple_adam = K.optimizers.Adam(lr=0.0001)\n",
    "textcnn = BuildTextCNN(maxlen=maxlen,max_features=len(vocab))\n",
    "textcnn.compile(loss='mean_squared_error', optimizer=simple_adam, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training \n",
      "WARNING:tensorflow:From /home/li/anaconda3/envs/ml/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "19100/19100 [==============================] - 52s 3ms/step - loss: 0.0286 - categorical_accuracy: 0.0440\n",
      "Epoch 2/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0252 - categorical_accuracy: 0.2248\n",
      "Epoch 3/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0225 - categorical_accuracy: 0.2104\n",
      "Epoch 4/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0213 - categorical_accuracy: 0.1211\n",
      "Epoch 5/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0210 - categorical_accuracy: 0.0718\n",
      "Epoch 6/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0208 - categorical_accuracy: 0.0693\n",
      "Epoch 7/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0207 - categorical_accuracy: 0.0741\n",
      "Epoch 8/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0206 - categorical_accuracy: 0.0783\n",
      "Epoch 9/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0204 - categorical_accuracy: 0.0742\n",
      "Epoch 10/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0203 - categorical_accuracy: 0.0780\n",
      "Epoch 11/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0202 - categorical_accuracy: 0.0790\n",
      "Epoch 12/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0200 - categorical_accuracy: 0.0808\n",
      "Epoch 13/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0198 - categorical_accuracy: 0.0806\n",
      "Epoch 14/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0197 - categorical_accuracy: 0.0806\n",
      "Epoch 15/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0194 - categorical_accuracy: 0.0845\n",
      "Epoch 16/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0192 - categorical_accuracy: 0.0903\n",
      "Epoch 17/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0189 - categorical_accuracy: 0.1002\n",
      "Epoch 18/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0187 - categorical_accuracy: 0.1116\n",
      "Epoch 19/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0183 - categorical_accuracy: 0.1241\n",
      "Epoch 20/20\n",
      "19100/19100 [==============================] - 51s 3ms/step - loss: 0.0180 - categorical_accuracy: 0.1349\n",
      "Training finished \n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_size = 1024\n",
    "max_epochs = 20\n",
    "print(\"Starting training \")\n",
    "h = textcnn.fit(train_x, train_y, batch_size=b_size, epochs=max_epochs, shuffle=True, verbose=1)\n",
    "print(\"Training finished \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = textcnn.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.01147663, 0.13769454, 0.14181189, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.55124813, 0.4935875 , 0.53773236,\n",
       "        0.520033  , 0.5210659 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01459757, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0],test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出分数不为0的项\n",
    "p_list = []\n",
    "for k in p:\n",
    "    p_tag = {}\n",
    "    for i, score in enumerate(k.tolist()):\n",
    "        if(score!=0):\n",
    "            p_tag[score] = i\n",
    "    p_list.append(p_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    return t/len(true_tag)\n",
    "\n",
    "def precision(true_tag, pre_tag):\n",
    "    t = 0\n",
    "    for i in pre_tag:\n",
    "        if(i in true_tag):\n",
    "            t += 1\n",
    "    if len(pre_tag) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return t/len(pre_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list_top5 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top5.append([p_list[i][k] for k in sorted(p_list[i].keys())][-5:])\n",
    "    \n",
    "p_list_top10 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top10.append([p_list[i][k] for k in sorted(p_list[i].keys())][-10:])\n",
    "    \n",
    "p_list_top116 = []\n",
    "for i in range(len(p_list)):\n",
    "    p_list_top116.append([p_list[i][k] for k in sorted(p_list[i].keys())][-116:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tag_real = []\n",
    "for row in test_y:\n",
    "    true_tag_real.append(row.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_seq (InputLayer)              (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 300, 64)      28590400    x_seq[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 299, 100)     12900       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 298, 100)     19300       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 297, 100)     25700       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 296, 100)     32100       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 1, 100)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 1, 100)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 1, 100)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1, 100)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 100)          0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 100)          0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 100)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 100)          0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 400)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          80200       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 116)          23316       dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,783,916\n",
      "Trainable params: 28,783,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "====================================\n",
      "Recall@116: 0.6548277033160039\n",
      "Precision@116: 0.271612746928828\n",
      "F1-score@116: 0.38650462226823884\n",
      "\n",
      "Recall@10: 0.6464797858546901\n",
      "Precision@10: 0.27416315775040107\n",
      "F1-score@10: 0.3850373062496468\n",
      "\n",
      "Recall@5: 0.475636222667792\n",
      "Precision@5: 0.42930736610648523\n",
      "F1-score@5: 0.4512858845818737\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "recal_at_116_count = 0\n",
    "recal_at_10_count = 0\n",
    "recal_at_5_count = 0\n",
    "precision_at_116_count = 0\n",
    "precision_at_10_count = 0\n",
    "precision_at_5_count = 0\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_10_count += recall(true_tag_real[i], p_list_top10[i])\n",
    "\n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_5_count += recall(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    recal_at_116_count += recall(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_10_count += precision(true_tag_real[i], p_list_top10[i])    \n",
    "\n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_5_count += precision(true_tag_real[i], p_list_top5[i])\n",
    "    \n",
    "for i in range(len(true_tag_real)):\n",
    "    precision_at_116_count += precision(true_tag_real[i], p_list_top116[i])\n",
    "    \n",
    "recall_at_116 = recal_at_116_count/len(true_tag_real)\n",
    "recall_at_10 = recal_at_10_count/len(true_tag_real)\n",
    "recall_at_5 = recal_at_5_count/len(true_tag_real)\n",
    "precision_at_116 = precision_at_116_count/len(true_tag_real)\n",
    "precision_at_10 = precision_at_10_count/len(true_tag_real)\n",
    "precision_at_5 = precision_at_5_count/len(true_tag_real)\n",
    "\n",
    "textcnn.summary()\n",
    "print()\n",
    "print(\"====================================\")\n",
    "print(\"Recall@116: {}\".format(recall_at_116))\n",
    "print(\"Precision@116: {}\".format(precision_at_116_count/len(true_tag_real)))\n",
    "print(\"F1-score@116: {}\".format((2*recall_at_116*precision_at_10)/(recall_at_116+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@10: {}\".format(recall_at_10))\n",
    "print(\"Precision@10: {}\".format(precision_at_10_count/len(true_tag_real)))\n",
    "print(\"F1-score@10: {}\".format((2*recall_at_10*precision_at_10)/(recall_at_10+precision_at_10)))\n",
    "print()\n",
    "print(\"Recall@5: {}\".format(recall_at_5))\n",
    "print(\"Precision@5: {}\".format(precision_at_5_count/len(true_tag_real)))\n",
    "print(\"F1-score@5: {}\".format((2*recall_at_5*precision_at_5)/(recall_at_5+precision_at_5)))\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "textcnn.save(\"../model/textcnn-{}.h5\".format(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
